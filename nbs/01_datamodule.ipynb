{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# from jax_learn.datamodule import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataModule\n",
    "\n",
    "> I'll will try to follow Lightning and Hydra attitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from abc import ABC, abstractmethod\n",
    "from enum import Enum\n",
    "from typing import Any, Tuple, List, Mapping, Callable\n",
    "import numpy as np\n",
    "from fastcore.test import test_eq, ExceptionExpected\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n",
    "\n",
    "It should:\n",
    "\n",
    "* transform items according to it's descriptor\n",
    "* compose some transforms together\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noop function \n",
    "Simply identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def noop(x): return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desc enum \n",
    "Possible descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Desc(Enum):\n",
    "  'Descriptors Enumeration'\n",
    "  IMAGE = 1\n",
    "  LABEL = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class Transform:\n",
    "  \n",
    "  dtype:np.dtype = np.float32\n",
    "  kinds:Mapping[Desc, Callable]\n",
    "\n",
    "  def __init__(self) -> None:\n",
    "    self.kinds = {}\n",
    "\n",
    "  def do(self, item, desc:Desc):\n",
    "    'Transform only items declared in `self.kinds`'\n",
    "    func = self.kinds.get(desc, noop)\n",
    "    return func(item)\n",
    "\n",
    "  def __call__(self, items: List[Any], descriptor: Tuple[str] = None) -> Any:\n",
    "    'Apply transformation to each item according to its descriptor'\n",
    "    descriptor = descriptor or self.descriptor\n",
    "    if not descriptor:\n",
    "      raise Exception(f'{self.__class__.__name__} got empty descriptor')\n",
    "    return [self.do(item, desc) for item, desc in zip(items, descriptor)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Compose(Transform):\n",
    "  transforms:List[Transform]\n",
    "\n",
    "  def __init__(self, transforms:List[Transform]) -> None:\n",
    "    self.transforms = transforms\n",
    "\n",
    "  def __call__(self, items: List[Any], descriptor:Tuple[Desc]) -> Any:\n",
    "    return [transform(items, descriptor) for transform in self.transforms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToFloat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ToFloat(Transform):\n",
    "  'Transform image to floating point'\n",
    "  def __init__(self, descriptor:Tuple[Desc] = None) -> None:\n",
    "    self.kinds = {Desc.IMAGE:self.image_to_float}\n",
    "    self.descriptor = descriptor\n",
    "\n",
    "  def image_to_float(self, item):\n",
    "    'Actual transformation'\n",
    "    return np.array(item, dtype=self.dtype) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform could get descriptor in constructor, the the transformation is static, or in a call itself, then the transformation is dynamic per call. Descriptor in the call takes precedence over given in a constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_image, label = np.random.randint(0,256,size=(32,32,3)), 5\n",
    "descriptor = (Desc.IMAGE, Desc.LABEL)\n",
    "# in constructor\n",
    "#\n",
    "tfm = ToFloat(descriptor)\n",
    "image, label = tfm([dummy_image, label])\n",
    "image_transformed = bool(0 <= image.all() and image.all() <= 1 and image.dtype==np.float32)\n",
    "test_eq(image_transformed, True)\n",
    "test_eq(label, 5)\n",
    "# in call\n",
    "#\n",
    "tfm = ToFloat()\n",
    "image, label = tfm([dummy_image, label], descriptor)\n",
    "image_transformed = bool(0 <= image.all() and image.all() <= 1 and image.dtype==np.float32)\n",
    "test_eq(image_transformed, True)\n",
    "test_eq(label, 5)\n",
    "# different descriptors in both\n",
    "#\n",
    "tfm = ToFloat((Desc.IMAGE, Desc.IMAGE, Desc.LABEL))\n",
    "image, label = tfm([dummy_image, label], descriptor)\n",
    "image_transformed = bool(0 <= image.all() and image.all() <= 1 and image.dtype==np.float32)\n",
    "test_eq(image_transformed, True)\n",
    "test_eq(label, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(Transform):\n",
    "\n",
    "  def __init__(self, descriptor:Tuple[Desc] = None, stats:Any = None) -> None:\n",
    "    self.kinds = {Desc.IMAGE:self.normalize}\n",
    "    self.descriptor = descriptor\n",
    "    if not isinstance(stats, (list, tuple, np.array)):\n",
    "      raise Exception(\n",
    "        f'Supported types for statistic are `list`, `tuple` or `np.array` got {type(stats)}')\n",
    "    self.stats = np.array(stats)\n",
    "\n",
    "  def normalize(self, item):\n",
    "    if item.shape[1:] != self.stats.shape:\n",
    "      raise Exception(\n",
    "        f'Expected shape is {self.stats.shape}, got {item.shape[1:]} (excluding batch dimension).')\n",
    "    return np.array(item, dtype=self.dtype) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to create pretty print function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataModule\n",
    "\n",
    "It should:\n",
    "* prepare dataset(s)\n",
    "* split the dataset(s)\n",
    "* transform items\n",
    "* create train and val (and maybe more) dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DataModule(ABC):\n",
    "  pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
